{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88733f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from cv2 import imread, createCLAHE \n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = os.path.join(\"lung/data/Lung Segmentation/CXR_png\")\n",
    "mask_path = os.path.join(\"lung/data/Lung Segmentation/masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31314764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mask that has modified name: 704\n"
     ]
    }
   ],
   "source": [
    "check = [i for i in mask if \"_mask\" in i]\n",
    "print(\"Total mask that has modified name:\",len(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d800b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 800/800 [01:25<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images length: 704\n",
      "Test masks length: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def getData(X_shape):\n",
    "    im_array = []\n",
    "    mask_array = []\n",
    "    for i in tqdm(images):  \n",
    "        # Görüntüyü oku\n",
    "        image_file = os.path.join(image_path, i)\n",
    "        if not os.path.exists(image_file):\n",
    "            #print(f\"Warning: Image file not found: {image_file}\")\n",
    "            continue\n",
    "        im = cv2.resize(cv2.imread(image_file), (X_shape, X_shape))[:, :, 0]\n",
    "        \n",
    "        # Maskeyi oku\n",
    "        mask_file = os.path.join(mask_path, i.split(\".png\")[0] + \"_mask.png\")\n",
    "        if not os.path.exists(mask_file):\n",
    "            #print(f\"Warning: Mask file not found: {mask_file}\")\n",
    "            continue\n",
    "        mask = cv2.resize(cv2.imread(mask_file), (X_shape, X_shape))[:, :, 0]\n",
    "        \n",
    "        im_array.append(im)\n",
    "        mask_array.append(mask)\n",
    "    \n",
    "    print(\"Test images length:\", len(im_array))\n",
    "    print(\"Test masks length:\", len(mask_array))\n",
    "    \n",
    "    return im_array, mask_array\n",
    "\n",
    "im_array, mask_array = getData(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ae7165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(im_array, mask_array, test_size = 0.2, random_state= 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c17bcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)\n",
    "y_train = np.array(y_train).reshape(len(y_train),dim,dim,1)\n",
    "X_test = np.array(X_test).reshape(len(X_test),dim,dim,1)\n",
    "y_test = np.array(y_test).reshape(len(y_test),dim,dim,1)\n",
    "assert X_train.shape == y_train.shape\n",
    "assert X_test.shape == y_test.shape\n",
    "images = np.concatenate((X_train,X_test),axis=0)\n",
    "mask  = np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6f3d1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "\n",
    "def unet(input_size=(256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7047280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "model = unet(input_size=(256,256,1))\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7ab30cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.7439 - loss: 0.5555\n",
      "Epoch 2/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - accuracy: 0.8267 - loss: 0.3714\n",
      "Epoch 3/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.9217 - loss: 0.2040\n",
      "Epoch 4/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.9428 - loss: 0.1542\n",
      "Epoch 5/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.9522 - loss: 0.1305\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_vol, validation_vol, train_seg, validation_seg = train_test_split(images/255.0,(mask>127).astype(np.float32), \n",
    "                                                                        test_size = 0.1,random_state = 127)\n",
    "\n",
    "train_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg,\n",
    "test_size = 0.1,\n",
    "random_state = 127)\n",
    "\n",
    "loss_history = model.fit(x = train_vol,\n",
    "                         y = train_seg,\n",
    "                         batch_size = 8,\n",
    "                  epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc8deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4dbecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
